{"pages":[{"title":"","text":"404","path":"404/404.html"}],"posts":[{"title":"Focal Loss for Dense Object Detection","text":"这篇文章研究了一阶段(one-stage)目标检测算法的检测性能劣于两阶段(two-stage)算法的原因—在单阶段检测算法中，前景和背景类别严重不平衡。因此文章定义了Focal Loss作为标准交叉熵（BCE）损失的改进用于解决该问题。在使用Focal Loss的基础上，作者实现了单阶段的目标检测算法RetinaNet，在具有单阶段目标检测算法的速度的基础上超过了目前SOTA的两阶段算法的准确率。 为什么需要Focal Loss我们知道object detection的算法主要可以分为两大类：two-stage detector和one-stage detector。前者是指类似Faster RCNN，RFCN这样需要region proposal的检测算法，这类算法可以达到很高的准确率，但是速度较慢。虽然可以通过减少proposal的数量或降低输入图像的分辨率等方式达到提速，但是速度并没有质的提升。后者是指类似YOLO，SSD这样不需要region proposal，直接采用回归算法的检测算法，这类算法速度很快，但是准确率不如前者。作者认为之所以one-stage detector的准确率不高，核心的问题是在这些算法的候选框中前景和背景的数目季度不平衡。在Yolo v2中，最后一层的输出为13x13x5，包含845个候选目标，但是在Ground Truth中只会有几个目标，因此有着严重的类别不平衡问题。 在这些候选目标中，由于很大一部分是负样本，即使负样本中有很多样本的分类效果已经较好，但是累加起来仍然会占据很大的比重，淹没那些难以分类的样本，使得有用的梯度信息被淹没在这些分类效果较好的样本中。 Focal Loss的形式Cross Entropy LossFocal Loss来源于交叉熵(CE)损失： ​ $$CE(p,y) = \\begin{cases}-log(p), &amp; y = 1 \\cr -log(1-p), &amp; otherwise. \\end{cases}$$ 如果是多分类问题，则: ​ $$ CE(p, y) = -log(p_y)​ $$ Balanced Cross Entropy Loss为了解决类别不平衡的问题，有人提出了Balances Cross Entropy Loss, $\\alpha$-balanced CE loss: ​ $$CE(p_t) = - \\alpha_tlog(p_t), \\alpha \\in [0, 1]$$ Focal Loss虽然$\\alpha$-balanced loss用于解决类别不平衡的问题，但是不能够分辨容易/困难的样本，因此作者在交叉熵的基础上添加了调节因子$(1-p_t)^\\gamma,\\gamma \\ge0$作为Focal Loss: ​ $$FL(p_t) = -(1-p_t)^\\gamma log(p_t)$$ 添加了调节因子之后，对于容易分类的样本$p_t$较大，则其产生的loss越小。在实际的应用中，作者对Focal loss也采用$\\alpha​$-balanced变形，在作者的实验中，该操作能够轻微的提高模型的准确率。 (Focal loss的具体形式不是很重要，作者在附录中也给出了其他形式的定义。) Focal Loss的有效性 上图是在一个训练好的模型中累计损失的分布，左边的为positive样本的分布，右边的为负样本的分布。在正样本中，20%的难以分类的数据占据了大约一半的loss，并且随着$\\gamma $的增加，难以分类的loss所占比重逐渐增加，但是变化幅度不大。在负样本的分布中，在$ \\gamma$为0是，分布和正样本的分布相似，但是随着$ \\gamma $的增加，负样本中难以分类的样本的loss所占的比重急速上升，在$\\gamma$为2时，几乎占据了所有的loss。在正常的BCE损失中，$\\gamma$为0，负样本中的容易分类的loss主导了梯度的方向，造成了单阶段检测器性能的下降。在$\\gamma$为2时，负样本中的大部分样本的损失可以忽略，只剩下负样本中难以分类的样本，难以分类的样本能够主导训练的梯度，能够改善类别不平衡的问题。 和OHEM(Online Hard Example Mining)以及Hinge的对比OHEMOHEM使用high-loss样本用于构建minibatches，通常用于两阶段检测器中。在OHEM中，每个样本通过其loss被评分，然后使用nms算法，再通过产生high-loss的样本构建minibatches。在构建的过程中nms threshold和batch size是可调节参数。OHEM也强调被错误分类的样本，和FL不同的是OHEM算法直接忽略了容易的样本。在作者的试样中，FL获得了比OHEM更高的准确率，表明相对于OHEM，FL更加的适用于Dense Detector中。 Hinge LossHinge Loss用于SVM中，形式为： ​ $$L(y, y’) = max(0, margin - (y - y’)) = max(0, margin + y’ - y) $$ 在作者的实验中采用hinge Loss不能获得稳定的有意义的结果。 RetinaNet Detector为了验证作者的想法，作者基于ResNet和FPN实现了RetinaNet目标检测算法。 RetinaNet采用由ResNet构建的FPN作为骨干网络，另外添加两个子网络用于分类和回归。第一个子网络以骨干网络的输出做分类，第二个子网络执行回归操作。 FPN Backbone作者采用FPN作为基础网络，FPN可以改进单张输入图片的多尺度信息， AnchorsClassification SubnetBox Reggression SubnetInitializationOptimization","path":"2019/03/21/focal-loss/"},{"title":"M2Det, A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network","text":"研究出发点特征金字塔(Feature pyramids)可以减轻目标实例大小多变的问题，广泛地运用于主流的目标检测器中(如DSSD, RetinaNet, RefineDet, Mask R-CNN, DetNet)，虽然使用特征金字塔使这些目标检测器获得了不错的效果，但是作者认为目前金字塔的设计都是基于固有的、应用于分类任务中的多尺度特征的简单融合，在目标检测任务中有一定的限制，因此作者提出了新的多等级特征金字塔网络，并且在SSD的基础上采用该金字塔网络，单模型的mAP达到了41%。 四种常用的特征金字塔，a是SSD中采用的特征金字塔，b是FPN中的特征金字塔，c是STDN中的特征金字塔，d是本文提出的方法MLFPN 具体方法模型的总体框架图如下(VGG作为基础网络)： FFMv1模块用于融合主网络的输出。FFMv1模块的输入为基础网络的较深层和较浅层的大小不同的特征图，用于提供多级的语义信息(multi-level semantic information)，FFMv1模块首先采用1x1的卷积核用于降低特征图的维度，然后对较小的特征图进行上采样，最后在通道方向拼接两个特征图，获得Base Feature，作为MLFPN的输入。 TUM模块用于获得更深层次的语义信息(深层通常有更强的语义信息)和浅层的定位信息。TUM模块产生一些具有不同规模的特征图。TUM模块可以有多级，其中第一级别的TUM的输入信息只来源于Base Feature，第2级别之后的TUM的输入为上一级别的TUM模块的输出的最大的feature map和Base Feature拼接后的结果(使用FFMv2模块进行拼接)。 TUM模块首先采用卷积层进行下采样，然后采用Blinear插值的方向进行下采样，然后把整个过程中的相同大小的Feature Map进行逐元素相加，再采用1x1大小的卷积核进行降维获取特征金字塔。 FFMv2模块用于融合TUM输出的最大的feature map和Base Feature，采用1x1的卷积核进行降维使用拼接操作进行融合。 Base Feature经过TUM之后，形成了多尺度(特征图大小)多层次(深度)（multi-scale and multi-scale)的特征金字塔信息，使用SFAM(Scale-wise Feature Aggregation Module)对不同尺度的特征进行重组和融合。基本操作是对不同深度TUM的输出，将相同尺度的特征进行concat，然后使用SE Attention对不同通道进行加权，得到最后的输出。 实验结果 不同模型的实验结果 速度 总结 MLFPN可以作为一种结合低层定位信息和高层语义信息的方法，可以应用于目标检测和语义分割等既需要语义信息，又需要位置信息的应用。 在多层次方面，使用FFMv2模块对TUM的特征和Base Feature的融合过程中，能否提出更有效的融合方式，比如考虑细节复杂的物体主要存在于更深层次中，在深层特征中减小浅层存在物体的权重。 能否直接使用TUM模块对图片进行特征提取？","path":"2019/03/20/m2det/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","path":"2019/03/19/hello-world/"}]}